{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kernelmans/my-ai-codes/blob/main/mini_reseau_sigmoide_re%CC%81tropropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90d1e71e",
      "metadata": {
        "id": "90d1e71e"
      },
      "source": [
        "# Mini réseau de neurones sigmoïde — apprentissage complet avec rétropropagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ac2277",
      "metadata": {
        "id": "24ac2277"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da84893",
      "metadata": {
        "id": "4da84893"
      },
      "outputs": [],
      "source": [
        "# Fonction sigmoïde et sa dérivée\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def sigmoid_derivative(a):\n",
        "    return a * (1 - a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed519d4",
      "metadata": {
        "id": "8ed519d4"
      },
      "outputs": [],
      "source": [
        "# Dataset XOR-like\n",
        "X_train = np.array([\n",
        "    [0.0, 0.0],\n",
        "    [0.0, 1.0],\n",
        "    [1.0, 0.0],\n",
        "    [1.0, 1.0]\n",
        "])\n",
        "\n",
        "y_train = np.array([0, 1, 1, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5a2e4f",
      "metadata": {
        "id": "8b5a2e4f"
      },
      "outputs": [],
      "source": [
        "# Initialisation des poids\n",
        "np.random.seed(0)\n",
        "w_h1 = np.random.randn(2)\n",
        "w_h2 = np.random.randn(2)\n",
        "b_h1 = 0.0\n",
        "b_h2 = 0.0\n",
        "\n",
        "w_out = np.random.randn(2)\n",
        "b_out = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a37a31",
      "metadata": {
        "id": "a8a37a31"
      },
      "outputs": [],
      "source": [
        "# Paramètres d'apprentissage\n",
        "eta = 0.1\n",
        "epochs = 1000\n",
        "loss_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f7b4267",
      "metadata": {
        "id": "7f7b4267"
      },
      "outputs": [],
      "source": [
        "# Entraînement\n",
        "for epoch in range(epochs):\n",
        "    total_error = 0\n",
        "    for x, y in zip(X_train, y_train):\n",
        "        # Forward pass\n",
        "        z1 = np.dot(w_h1, x) + b_h1\n",
        "        a1 = sigmoid(z1)\n",
        "\n",
        "        z2 = np.dot(w_h2, x) + b_h2\n",
        "        a2 = sigmoid(z2)\n",
        "\n",
        "        hidden_output = np.array([a1, a2])\n",
        "\n",
        "        z_out = np.dot(w_out, hidden_output) + b_out\n",
        "        y_hat = sigmoid(z_out)\n",
        "\n",
        "        # Erreur\n",
        "        error = 0.5 * (y_hat - y) ** 2\n",
        "        total_error += error\n",
        "\n",
        "        # Backpropagation\n",
        "        delta_out = (y_hat - y) * sigmoid_derivative(y_hat)\n",
        "\n",
        "        # Mise à jour sortie\n",
        "        w_out -= eta * delta_out * hidden_output\n",
        "        b_out -= eta * delta_out\n",
        "\n",
        "        # Deltas cachés\n",
        "        delta_h1 = sigmoid_derivative(a1) * delta_out * w_out[0]\n",
        "        delta_h2 = sigmoid_derivative(a2) * delta_out * w_out[1]\n",
        "\n",
        "        w_h1 -= eta * delta_h1 * x\n",
        "        b_h1 -= eta * delta_h1\n",
        "\n",
        "        w_h2 -= eta * delta_h2 * x\n",
        "        b_h2 -= eta * delta_h2\n",
        "\n",
        "    loss_history.append(total_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "972636db",
      "metadata": {
        "id": "972636db"
      },
      "outputs": [],
      "source": [
        "# Affichage de la courbe d'apprentissage\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(loss_history)\n",
        "plt.title(\"Évolution de l'erreur pendant l'entraînement\")\n",
        "plt.xlabel(\"Époque\")\n",
        "plt.ylabel(\"Erreur cumulée (loss)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec705439",
      "metadata": {
        "id": "ec705439"
      },
      "outputs": [],
      "source": [
        "# Prédictions après entraînement\n",
        "print(\"=== Prédictions après entraînement ===\")\n",
        "for x, y in zip(X_train, y_train):\n",
        "    z1 = np.dot(w_h1, x) + b_h1\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    z2 = np.dot(w_h2, x) + b_h2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    hidden_output = np.array([a1, a2])\n",
        "    y_hat = sigmoid(np.dot(w_out, hidden_output) + b_out)\n",
        "\n",
        "    print(f\"Entrée : {x}, Prédit : {round(y_hat, 3)}, Attendu : {y}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}